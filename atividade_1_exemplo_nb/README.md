# Atividade 1: Classifica√ß√£o com Naive Bayes

## Descri√ß√£o

Implementa√ß√£o e compara√ß√£o de tr√™s variantes do classificador Naive Bayes aplicados ao dataset Congressional Voting Records. O objetivo √© analisar o comportamento de diferentes algoritmos Naive Bayes em dados categ√≥ricos bin√°rios e demonstrar a import√¢ncia da escolha do algoritmo adequado ao tipo de dados.

## Objetivo

Comparar o desempenho de tr√™s variantes do Naive Bayes (BernoulliNB, GaussianNB e MultinomialNB) na classifica√ß√£o de partidos pol√≠ticos baseando-se em padr√µes de vota√ß√£o do Congresso dos EUA em 1984.

## Dataset

**Congressional Voting Records (1984)**
- **Fonte**: UCI Machine Learning Repository
- **URL**: https://archive.ics.uci.edu/static/public/105/data.csv
- **Caracter√≠sticas**:
  - 435 inst√¢ncias (ap√≥s limpeza)
  - 17 atributos (16 features + 1 target)
  - **Target**: Partido pol√≠tico (Democrat ou Republican)
  - **Features**: Votos em 16 quest√µes pol√≠ticas (yes/no)
  - Valores ausentes representados por '?'

### Quest√µes Pol√≠ticas Analisadas

1. Handicapped infants
2. Water project cost sharing
3. Adoption of the budget resolution
4. Physician fee freeze
5. El Salvador aid
6. Religious groups in schools
7. Anti-satellite test ban
8. Aid to Nicaraguan contras
9. MX missile
10. Immigration
11. Synfuels corporation cutback
12. Education spending
13. Superfund right to sue
14. Crime
15. Duty-free exports
16. Export administration act South Africa

## Metodologia

### 1. Pr√©-processamento

#### Convers√£o de Dados
- **Votos**: 'y' ‚Üí 1, 'n' ‚Üí 0
- **Partido**: 'democrat' ‚Üí 0, 'republican' ‚Üí 1

#### Limpeza de Dados
- Remo√ß√£o de inst√¢ncias com target ausente
- Tratamento adequado de valores ausentes nas features

#### Divis√£o dos Dados
- **Treino**: 70% (304 inst√¢ncias)
- **Teste**: 30% (131 inst√¢ncias)
- **Random state**: 42 (para reprodutibilidade)

#### Imputa√ß√£o de Valores Ausentes
- Estrat√©gia: `most_frequent`
- Aplica√ß√£o: Apenas no conjunto de treino
- **Importante**: Imputa√ß√£o realizada AP√ìS a divis√£o treino/teste para evitar data leakage

### 2. Modelos Avaliados

#### üèÜ BernoulliNB
- **Descri√ß√£o**: Projetado especificamente para features bin√°rias ou booleanas
- **Adequa√ß√£o**: IDEAL para o dataset (votos sim/n√£o)
- **Vantagem**: Modela explicitamente a presen√ßa/aus√™ncia de features bin√°rias

#### GaussianNB
- **Descri√ß√£o**: Assume distribui√ß√£o gaussiana (normal) das features
- **Adequa√ß√£o**: INADEQUADO para dados bin√°rios discretos
- **Limita√ß√£o**: Distribui√ß√£o normal n√£o √© apropriada para dados bin√°rios

#### MultinomialNB
- **Descri√ß√£o**: Projetado para contagens discretas (ex: frequ√™ncia de palavras)
- **Adequa√ß√£o**: N√ÉO-IDEAL para dados bin√°rios simples
- **Limita√ß√£o**: Melhor para dados de contagem com m√∫ltiplos valores poss√≠veis

## Resultados

### M√©tricas de Performance

| Modelo | Acur√°cia | Precis√£o (macro) | Recall (macro) | F1-Score (macro) | Adequa√ß√£o |
|--------|----------|------------------|----------------|------------------|-----------|
| **BernoulliNB** | **94.62%** | **0.95** | **0.93** | **0.94** | ‚úÖ Apropriado |
| GaussianNB | 93.85% | 0.94 | 0.92 | 0.93 | ‚ùå Inadequado |
| MultinomialNB | 92.31% | 0.93 | 0.91 | 0.92 | ‚ö†Ô∏è N√£o-ideal |

### An√°lise Detalhada - BernoulliNB (Melhor Modelo)

```
              precision    recall  f1-score   support

    Democrat       0.94      0.98      0.96        82
  Republican       0.96      0.89      0.92        48

    accuracy                           0.95       130
   macro avg       0.95      0.93      0.94       130
weighted avg       0.95      0.95      0.95       130
```

#### Matriz de Confus√£o - BernoulliNB

|                | Predito: Democrat | Predito: Republican |
|----------------|-------------------|---------------------|
| **Real: Democrat** | 80 (VP) | 2 (FN) |
| **Real: Republican** | 5 (FP) | 43 (VN) |

- **VP (Verdadeiros Positivos)**: 80 democratas corretamente classificados
- **VN (Verdadeiros Negativos)**: 43 republicanos corretamente classificados
- **FP (Falsos Positivos)**: 5 republicanos classificados como democratas
- **FN (Falsos Negativos)**: 2 democratas classificados como republicanos

### Visualiza√ß√µes Inclu√≠das

1. **Gr√°fico Comparativo de Acur√°cia**: Compara√ß√£o visual entre os tr√™s modelos
2. **Matriz de Confus√£o**: An√°lise detalhada dos erros de classifica√ß√£o
3. **Relat√≥rio de Classifica√ß√£o**: M√©tricas completas por classe

## Insights e Descobertas

### 1. Import√¢ncia da Escolha do Algoritmo
- **BernoulliNB superou os demais** em 2.31% de acur√°cia comparado ao MultinomialNB
- A diferen√ßa de performance ilustra a import√¢ncia de escolher o algoritmo adequado ao tipo de dados
- Algoritmos inadequados (GaussianNB, MultinomialNB) ainda apresentam resultados razo√°veis, mas sub√≥timos

### 2. Caracter√≠sticas dos Dados
- Dados bin√°rios de vota√ß√£o s√£o naturalmente adequados para BernoulliNB
- Padr√µes de vota√ß√£o s√£o consistentes dentro de cada partido
- Alta correla√ß√£o entre votos espec√≠ficos e filia√ß√£o partid√°ria

### 3. Performance por Classe
- **Democrats**: 98% de recall (excelente detec√ß√£o)
- **Republicans**: 96% de precision (baixo erro de falsos positivos)
- Modelo ligeiramente melhor em identificar democratas

### 4. Tratamento de Valores Ausentes
- Estrat√©gia `most_frequent` efetiva para dados bin√°rios
- Imputa√ß√£o ap√≥s divis√£o treino/teste evita data leakage
- Valores ausentes n√£o prejudicaram significativamente a performance

## Limita√ß√µes e Considera√ß√µes

### Limita√ß√µes do Dataset
- Dataset hist√≥rico (1984) pode n√£o refletir padr√µes atuais
- N√∫mero limitado de inst√¢ncias (435)
- Apenas duas classes (sistema bipartid√°rio)

### Limita√ß√µes do Modelo
- Naive Bayes assume independ√™ncia entre features (nem sempre verdadeiro)
- Padr√µes de vota√ß√£o podem ter depend√™ncias n√£o capturadas
- Modelo simples pode n√£o capturar rela√ß√µes complexas

### Considera√ß√µes Pr√°ticas
- Alta acur√°cia n√£o garante generaliza√ß√£o para novos contextos pol√≠ticos
- Modelo treinado em dados hist√≥ricos espec√≠ficos
- Requer retreinamento com dados atuais para aplica√ß√£o pr√°tica

## Tecnologias Utilizadas

- **Python 3.x**
- **pandas**: Manipula√ß√£o e an√°lise de dados
- **numpy**: Opera√ß√µes num√©ricas
- **scikit-learn**: 
  - `BernoulliNB`, `GaussianNB`, `MultinomialNB`
  - `train_test_split`
  - `SimpleImputer`
  - M√©tricas de avalia√ß√£o
- **matplotlib**: Visualiza√ß√µes
- **seaborn**: Gr√°ficos estat√≠sticos avan√ßados

## Estrutura do Notebook

1. **Importa√ß√£o de Bibliotecas**
2. **Carregamento de Dados**
   - Download do UCI Repository
   - Inspe√ß√£o inicial
3. **Prepara√ß√£o dos Dados**
   - Convers√£o de categorias para num√©ricos
   - Limpeza de valores ausentes no target
4. **An√°lise Explorat√≥ria**
   - Estat√≠sticas descritivas
   - Distribui√ß√£o de classes
5. **Divis√£o Treino/Teste**
   - 70/30 split com random_state=42
6. **Tratamento de Valores Ausentes**
   - SimpleImputer com estrat√©gia 'most_frequent'
7. **Treinamento do Modelo BernoulliNB**
   - Fit e predict
   - Avalia√ß√£o de performance
8. **Comparativo com Outros Modelos**
   - GaussianNB
   - MultinomialNB
9. **Visualiza√ß√£o de Resultados**
   - Matriz de confus√£o
   - Gr√°fico comparativo
   - Relat√≥rio de classifica√ß√£o

## Como Executar

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/cbdocid25/machine-learning-aplicado-II.git
```

2. Navegue at√© o diret√≥rio:
```bash
cd machine-learning-aplicado-II/Atividade_1_exemplo_nb
```

3. Instale as depend√™ncias:
```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

4. Execute o notebook:
```bash
jupyter notebook atividade_1_exemplo_nb.ipynb
```

## Arquivos

- `atividade_1_exemplo_nb.ipynb`: Notebook principal com an√°lise completa
- `comparativo_modelos_nb.png`: Gr√°fico comparativo de acur√°cia dos modelos
- `README.md`: Esta documenta√ß√£o

## Conclus√µes

### Principais Aprendizados

1. **BernoulliNB √© superior para dados bin√°rios**: Confirma teoricamente e empiricamente
2. **Escolha do algoritmo importa**: 2.31% de diferen√ßa em acur√°cia
3. **Tratamento adequado de dados √© crucial**: Evitar data leakage na imputa√ß√£o
4. **Naive Bayes √© eficiente**: Simplicidade com boa performance

### Recomenda√ß√µes

**Para Classifica√ß√£o de Dados Bin√°rios:**
- Sempre preferir BernoulliNB
- Considerar outros algoritmos apenas se necess√°rio
- Validar adequa√ß√£o do modelo ao tipo de dado

**Para Trabalhos Futuros:**
- Testar outros algoritmos (Random Forest, SVM, Logistic Regression)
- An√°lise de features importantes
- Cross-validation para robustez
- Aplica√ß√£o em datasets pol√≠ticos mais recentes

## Refer√™ncias

- [UCI Machine Learning Repository - Voting Records](https://archive.ics.uci.edu/dataset/105/congressional+voting+records)
- [Scikit-learn Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)
- [BernoulliNB Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)

## Autor

**cbdocid25**

## Institui√ß√£o

Universidade do Estado do Amazonas (UEA)  
P√≥s-Gradua√ß√£o em Ci√™ncias de Dados  
Disciplina: Machine Learning Aplicado II  
Ano: 2025
